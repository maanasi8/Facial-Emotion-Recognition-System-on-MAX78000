# FACIAL EMOTION RECOGNITION
## Introduction
Facial emotion recognition(FER) is the process of detecting human emotions from facial expressions using computer vision and machine learning/ deep learning algorithms. Understanding emotions can help improve human-machine interactions, personalized digital marketing, and mental health diagnosis. Facial recognition systems use features such as eye movements, facial muscle movements, and lip position to classify emotions. Recognition of human emotions is a vital phase, which is involved in several applications such as augmented and virtual reality, advanced driver assistance systems, human-computer interaction, and security systems. Due to the growing demand for Facial Emotion Recognition (FER) in recent times, the current study deals with the identification of human emotions.
## Problem Statement
Develop a synthesizable AI model to perform image classification on facial emotions using a deep neural network.
## Objectives
1.  Preprocessing of the images.
2.  Building and training the classification model to classify the facial emotions of humans.
3.  Testing or performance analysis of the model.
4. Comparing the synthesizable model's accuracy and efficiency with state-of-the-art techniques for facial emotion recognition.
## Scope & Constraint
1. The dataset is constrained to 7 emotion classes.
2. The dataset consists of grey-scale images only. Hence, it inherently demands less computational power and is more energy-efficient compared to datasets involving color images.

## Intermediate Results:
![Figure_1](https://github.com/maanasi8/Mini-Project/assets/126388400/9963e409-ae8c-46d0-9c70-a9cc3f5d6b1d)
![Figure_2](https://github.com/maanasi8/Mini-Project/assets/126388400/f9a1cba9-60f3-4989-b7d1-9df2e12bdc3e)
