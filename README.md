# FACIAL EMOTION RECOGNITION
## Introduction
Facial emotion recognition(FER) is the process of detecting human emotions from facial expressions using computer vision and machine learning/ deep learning algorithms. Understanding emotions can help improve human-machine interactions, personalized digital marketing, and mental health diagnosis. Facial recognition systems use features such as eye movements, facial muscle movements, and lip position to classify emotions. Recognition of human emotions is a vital phase, which is involved in several applications such as augmented and virtual reality, advanced driver assistance systems, human-computer interaction, and security systems. Due to the growing demand for Facial Emotion Recognition (FER) in recent times, the current study deals with the identification of human emotions.
## Problem Statement
Develop a synthesizable AI model to perform image classification on facial emotions using a deep neural network.
## Objectives
1.  Preprocessing of the images.
2.  Building and training the classification model to classify the facial emotions of humans.
3.  Testing or performance analysis of the model.
4. Comparing the synthesizable model's accuracy and efficiency with state-of-the-art techniques for facial emotion recognition.
## Scope & Constraint
1. The dataset is constrained to 7 emotion classes.
2. The dataset consists of grey-scale images only. Hence, it inherently demands less computational power and is more energy-efficient compared to datasets involving color images.
## Software Engineering Requirements
### Functional requirements:
1. The user shall be able to input the grayscale facial images for emotion recognition.
2. The system shall classify a range of emotions such as happiness, sadness, anger, fear, etc., from the input images.
3. The system shall predict the emotions and generate scores/accuracies for all the emotion classes.
4. The user shall be able to view the performance analysis.
### Non-Functional requirements:
1. The system should achieve a response time of less than 2 seconds for emotion recognition processing, ensuring minimal delay in emotion recognition to enhance user experience.
2. The emotion recognition system should achieve a minimum accuracy of 70% on standardized emotion recognition benchmarks.
## Dataset description
### Facial emotion recognition
https://www.kaggle.com/datasets/chiragsoni/ferdata__
 Dataset size: 56.51MB.__
 The dataset contains 35,914 grayscale images of faces.__
 Testing images – 20.06% [7,205 images]
 Training images – 79.93% [28,709 images]
 The dataset consists of 7 classes. They are- Happy, sad, disgust, angry, fear, neutral, and surprise.
 The number of images for each feature is as follows- 
angry – 4953 images
disgust - 547 images
fear - 5121 images
Happy - 8989 images
neutral - 6198 images
sad - 6077 images
surprise - 4002 images
 The images in the dataset are approximately of the size 2KB each.

## Intermediate Results:
![Figure_1](https://github.com/maanasi8/Mini-Project/assets/126388400/9963e409-ae8c-46d0-9c70-a9cc3f5d6b1d)
![Figure_2](https://github.com/maanasi8/Mini-Project/assets/126388400/f9a1cba9-60f3-4989-b7d1-9df2e12bdc3e)
